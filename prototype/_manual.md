# Manual

The manual gives you a quick overview of the system and how to get setup for further development and how to use the final proof of concept.

## System Manual

This part of the manual gives a quick overview of the entire system to understand the underlying structure of the project and how to setup the system.

### Technology Stack

In the following image, you can see an outline of our technology stack.

![Technology Stack Image]({{ site.baseurl }}/assets/photos/technology-stack.png)

We are using the [flask](http://flask.pocoo.org/) web framework together with a [PostgreSQL](http://www.postgresql.org/) database. [SQLAlchemy](http://www.sqlalchemy.org/) and [psycopg2](http://initd.org/psycopg/) are used to write SQL queries to the database in Python. Finally to provide real-time data to the client, we use [Flask-SocketIO](https://flask-socketio.readthedocs.org/en/latest/).

In the front-end, we also use [socket.io](http://socket.io/) to manage the web socket on the client's side. [D3.js](https://d3js.org/) and [leaflet.js](http://leafletjs.com/) are then used to visualize all of the report matchings. Finally other helper libraries used are: [lodash.js](https://lodash.com/), [moment.js](http://momentjs.com/) and [jquery](https://jquery.com/).

Most of the data provided came in a variety of formats. First of all, the diagrams are all txt files. The specifications of what specific characters mean can be found [here](http://www.atoc.org/download/clientfiles/files/RSPDocuments/RSPS5046%2001-00%20Timetable%20Information%20Data%20Feed%20Interface%20Specification.pdf). Most of the other data was in a more comprehensible format such XML (GPS and TRUST reports) and CSV (Unit to GPS mapping and genius allocations).

### Setting Up

To get started, you will need to install [pip](https://pip.pypa.io/en/stable/installing/), [git](https://confluence.atlassian.com/bitbucket/set-up-git-744723531.html), [PostgreSQL](http://www.postgresql.org/download/) (and [brew](http://brew.sh/), if you're using a mac).

#### Setting Up the Database

Create a postgres database with `psql` (installed with PostgreSQL):

```
CREATE USER atos WITH PASSWORD 'atos';
CREATE DATABASE atos WITH OWNER atos;
GRANT ALL PRIVILEGES ON DATABASE atos TO atos;
```

#### Setting Up a Local Environment

First, you will need to install `virtualenv` using pip:

```
pip install virtualenv
```

After you have virtualenv installed, create a virtual environment:

```
virtualenv venv
```

In your new virtual environment, clone the repository and cd into the correct repository

```
git clone https://github.com/ucl-team-8/service.git service
cd service
```

Then run these bash commands to set the environment variables in your virtual environment `activate` file:

```
echo "export APP_SETTINGS='config.DevelopmentConfig'" >> venv/bin/activate
echo "export DATABASE_URL='postgres://atos:atos@localhost/atos'" >> venv/bin/activate
```

Activate your virtual environment by running:

```
source venv/bin/activate
```

Finally, install all dependencies from `requirements.txt`:

```
pip install -r requirements.txt
```

#### Installing Visualisation Dependencies

To install `node` and `npm` on a Mac, run:

```
brew install node
```

If you don't have brew, see installation instructions [here](http://brew.sh/).

To install `node` and `npm` on Windows, download it from [nodejs.org](https://nodejs.org/en/download/).

After you have `npm`, run:

```
npm install -g jspm
npm install
jspm install
```

Finally, your local environment should be set up.

#### Creating the Database Tables

We use `Flask-Migrate` to handle database migrations. To create the necessary database tables, run:

```
python manage.py db upgrade
```

#### Importing Data

You will first need to get a copy of the `locations.tsv` file with all of the TIPLOC locations. This file is not publicly available since it is considered confidential information.

To import all of the data in the `data` directory, either run:

```
python import/import.py northern_rail
```

or:

```
python import/import.py east_coast
```

depending on which data set you would like to import.

### Folder Structure

```
.
├── algorithm           # Old iteration of the algorithm
├── algorithm2          # Improved version of the algorithm
├── data                # All of the sample data
|   ├── east_coast      # Extract from the east coast
|      └── ...
|   ├── northern_rail    # Extract from northern rail
|      └── ...
|   ├── locations.tsv   # gitignored file with locations of tiplocs
├── import              # Contains the import script to import data into database.
├── migrations          # All of the database generated by alembic
├── static              # The static files for the client
|   ├── css
|   ├── data            # Can be ignored, is used if you want to directly serve a data file to the client
|   ├── images
|   ├── js          
|      ├── live         # All of the code for the prototype application on client.
|         ├── map       # Uses D3 and leaflet to visualise matching on a map
|         ├── reports   # Renders the reports next to the map
|         ├── services  # Shows all of the services and search
|         ├── utils     # All utility functions
|         └── index.js  # Combines all of the functionality
|   └── ...
├── templates           # All of the html templates that can be rendered
├── tests               # Folder with all of the tests for the python code
├── app_socketio.py     # Deals with clients connecting through socketio
├── app.py              # Serves all of the html web pages
├── config.py           # Flask configurations
├── manage.py           # Manages database models and migrations
├── models.py           # All of the database models
├── package.json        # npm dependencies
├── README.md
├── requirements.txt    # Python packages used
└── ...
```

## User manual

### UI

<a href="{{ site.baseurl }}/visualisations/demo/">
  <img src="{{ site.baseurl }}/assets/photos/demo.png" alt="A demo of the user interface" style="width: 100%"/>
</a>

([See a demo of the UI]({{ site.baseurl }}/visualisations/demo/))

The UI is divided up into three vertical panes.

#### Left pane

On the left are all the **services** that the algorithm has seen so far. There are some numbers in coloured circles:

- **green** is the number of **new** matchings found that **didn't** exist in the allocations
- **gray** is the number of matchings found that **did** already exist in the allocations
- **red** is the number of matchings that **did** exist in the allocations, but are **wrong** according to the algorithm

The services that are "interesting" (red and green) are shown first in the list, and the "boring" (gray) are last.

The **search field** at the top allows searching for:

- a headcode (e.g. `2C07`)
- a gps_car_id (e.g. `150148`), which will find all services for the gps_car_id
- `added` will find services with **green** circles
- `unchanged` will find services with **gray** circles
- `removed` will find services with **red** circles

Selecting a service will show more information in the middle and right pane.

#### Middle pane

The middle pane shows a **map** with:

- TRUST reports of the service in **green**
- GPS reports of the unit in **brown**

Only the selected service is plotted by default, but you can plot matchings by moving your mouse over them in the right pane.

You can also zoom by scrolling (or the **+** and **-** buttons) and pan by dragging. The current time of the simulation is shown in the top right corner (if the simulation is running).

#### Right pane

The right pane shows matchings of the selected service with different units.

At the top is the **headcode** or **gps_car_id**. If they are shown in **green** then the algorithm decided that they **match**, otherwise, if they're in **red**, then they **do not match**, but are planned in the allocations.

Below them are the reports. In **green** are TRUST reports of the service, and in **brown** are GPS reports of the unit. The reports are sorted **chronologically**, with earliest at the top and latest and the bottom.

Moving your mouse over the reports will display on the map the approximate, interpolated location of the service and the unit at that specific time. This helps determine how close they were running, and whether they do indeed match.
