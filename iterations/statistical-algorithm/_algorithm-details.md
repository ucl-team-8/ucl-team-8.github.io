This is the **final iteration** of the algorithm. It took many ideas and evaluations to reach this stage, some of which weren't documented, and others that fortunately were. If you're interested in precursors to the ideas discussed here, read about our [first]({{ site.baseurl }}/iterations/simple-algorithm) and [second]({{ site.baseurl }}/iterations/segments-algorithm) iterations. 
{: .lead}

# Summary

The algorithm is composed of multiple layers—and effectively, multiple components—where each layer has a distinct purpose. Each layer takes its input from a dedicated storage component and stores its output in another dedicated storage component. The reports roughly "flow" through the system as follows:

- The **event matcher** matches up any two reports that are within a set time tolerance (e.g. 5 minutes) and occurred at the same TIPLOC. It then passes on these event matchings onto the service matcher.
- The **service matcher** takes the event matchings and creates new service matchings and updates existing ones. (A single service matching is composed of a service, a unit and some properties between their matched events, like mean time difference.) The service matcher does no filtering—if there is a single event matching corresponding to a single service and a unit, a service matching is produced. The event matchings are discarded after each run of the service matcher, but service matchings persist on the database.
- Since the service matcher does no filtering, there are lots of improbable service matchings created. The **matchings** component takes service matchings from the database and filters the most likely matchings for every unit. This is where the decision on what a _good matching_ is made, based on:
  - the properties of a service matching, calculated by the service matcher
  - the (genius) allocations given, as part of the extract

# Detailed explanation

## Simulator

The **simulator** is responsible for simulating a real-time environment for the algorithm. It gets reports from the extract, which is stored in the database, and passes the reports onto the **event matcher**. It always gets and processes whatever the next report is, so effectively "simulated time" is not linear but is dictated by the "spacing" between reports. This way, the algorithm runs and terminates as quickly as it possibly can, allowing us to better estimate performance.

TRUST and GPS reports are represented as Python dictionaries, parsed from and containing all the original fields of the extract:

#### TRUST

```python
{
  'id': Integer, # a unique ID, generated by the system
  'headcode': String,
  'origin_location': String,
  'origin_departure': DateTime,
  'tiploc': String,
  'seq': Integer,
  'event_type': String,
  'event_time': DateTime,
  'planned_pass': Boolean
}
```

#### GPS

```python
{
  'id': Integer, # a unique ID, generated by the system
  'gps_car_id': String,
  'event_type': String,
  'tiploc': String,
  'event_time': DateTime
}
```

## Event matcher

The event matcher is the first layer of the algorithm. It's the component that the reports are passed onto to be processed and its task is to match up TRUST and GPS reports that occurred at the same TIPLOC within 5 minutes of each other. It does this by keeping 30 minute caches of the latest TRUST and GPS reports that occurred at every TIPLOC. Additionally, the event matcher also updates the **tracker**, which holds some statistics about services and units for quick access.

### Caches

To match up reports, the event matcher keeps 2 caches—one of TRUST and one of GPS reports. The caches are optimized to hold time-limited data, indexed by TIPLOC.

In our prototype, the cache uses a Python dictionary, with TIPLOC as key and a list of sorted reports as value.

## Tracker

For each service and unit, the tracker keeps track of:

- The identifiers for all the services and units that were "seen"
- The total number of reports from each service/unit
- The times of the first and last reports received for each service/unit

This data is used at a later stage, when services are matched with units.

## Queue

The event matcher passes on matching reports to the **queue**. The queue stores an event matching as a dictionary, like so:

#### Event matching

```python
{
  'trust_id': Integer,
  'gps_id': Integer,
  'trust_event_time': DateTime,
  'gps_event_time': DateTime
}
```

The **id**s are kept to test for uniqueness later, and the **event time**s to calculate the mean time error.

Event matchings are stored in lists, depending on the service and unit it belongs to, and the whole data structure is a Python dictionary which has "service matching keys", which are Python tuples:

#### Service matching key

```python
(headcode, origin_location, origin_departure, gps_car_id)
```

The first 3 values essentially represent a service and come from the TRUST report, whereas the last represents a unit and comes from the GPS report. The complete data structure looks like:

```python
{
  [service matching key]: [
    [event matching],
    [event matching],
    [event matching],
    ...
  ],
  [service matching key]: [
    ...
  ]
}
```

The queue is emptied whenever the event matchings are retrieved.

## Service matcher

From the queue, the reports are passed onto the **service matcher**. The service matcher runs periodically (15 minutes in our prototype) and processes all event matchings that are in the queue. For every service matching key in the queue, the service matcher either updates the service matching (if it exists in the database) or creates a new service matching. Once it finishes, it notifies the **matchings** component with the keys of the service matchings that have changed.

Service matchings are stored in the database, but the database rows are represented as equivalent Python dictionaries while being manipulated. Below is the structure of a service matching:

#### Service matching

```python
{
  'headcode': String,
  'origin_location': String,
  'origin_departure': DateTime,
  'gps_car_id': String,
  'mean_time_error': Float, # in minutes
  'variance_time_error': Float, # in minutes^2
  'total_matching': Integer,
  'start': DateTime,
  'end': DateTime
}
```

- The `headcode`, `origin_location`, `origin_departure` and `gps_car_id` come from the service matching key, which as we mentioned, is stored in the queue.
- A _time error_ is considered the time difference between matched TRUST and GPS reports. The `mean_time_error` is the mean of time errors of all event matchings for a given service matching key, and `variance_time_error` their calculated variance.
- The `total_matching` field holds the total number of (unique) TRUST reports that were matched with a GPS report.
- The `start` and `end` fields store the start and end times of the service matching.

### New service matchings

For new service matchings that don't exist on the database (or rather, service matchings keys that don't exist in the database), the fields above are calculated from all the event matchings received from the queue for the given service matching key.  

- To calculate `mean_time_error`, we use the standard formula:

```python
mean = sum(time_errors) / len(time_errors)
```

- Likewise for `variance_time_error`:

```python
variance = sum((mean - value)**2 for value in time_errors) / len(time_errors)
```

- To count the `total matching` TRUST reports, we count the total unique `trust_id`s in the event matchings.
- The `start`/`end` times of the service matching are the earliest/latest `trust_event_time` or `gps_event_time` (whichever is earliest/latest) in the event matchings.

### Existing service matchings

When a service matchings already exists in the database, a new service matching is created from the event matchings in the queue, and fields calculated (as above). The two (existing and new) service matchings are then combined:

- `headcode`, `origin_location`, `origin_departure` and `gps_car_id` are the same in both existing and new service matchings, since they represent the service matching key.
- `mean_time_error` and `variance_time_error` are combined from the two, using Youngs and Cramer updating formulas (adapted from [this paper](http://www.jstor.org/stable/2683386)).
- `total_matching` are simply added from the two service matchings
- `start` is simply the earliest `start` of the two service matchings, and `end` the latest `end`.

## Matchings

In the final layer, the **matchings** component filters only the most likely matchings—these will essentially say which unit ran which service. It also keeps and updates a local copy of **unit matchings**, which are simply all the service matchings that were assigned to a specific unit.

The **matchings** component stores gets notified by the **service matcher** about the keys of the service matchings that have changed. Every time the matchings component receives a notification:

1. It extracts the unique `gps_car_id`s from the changed service matching keys. These are the units for which at least one service matching was changed. For each `gps_car_id`, it:
  1. Retrieves all the service matchings in the database that belong to it.
  2. Filters out service matchings that do not satisfy the **minimum matching criteria** (more below).
  3. Assigns a **score** to each service matching remaining and sorts them by descending score (more below).
  4. It traverses the sorted list of service matchings and assigns each to the `gps_car_id` if it **doesn't overlap** (in time) with a previously assigned matching. If it **does overlap**, it simply ignores it and moves on to the next.

At the end of this process, the **unit matchings** stored locally are updated, and can be retrieved by an external system (in our case, the visualisation).

### Minimum matching criteria

We mentioned that the **matchings** component filters out service matchings that do not satisfy the minimum matching criteria. These criteria are as follows:

- If a service matching is in the predetermined allocations, then it does satisfy the minimum criteria, regardless of other properties.
- If a service matching is not in the allocations, then it only satisfies the criteria if all of the following are true for the service matching:
  - The `total_matching` number of reports is greater than 2
  - The `variance_time_error` is less than 6.0
  - The absolute of the `mean_time_error` is less than 1.5
  - If the service has less than 6 `total_matching` number of reports, then:
    - its `variance_time_error` needs to be less than 2
    - the absolute of the `mean_time_error` less than 1.0
  - If the service matching time length (`end - start`) is less than 15 minutes, then it has to match 35% of the total reports of the service

The criteria are all calculated from the fields that are stored in each service matching that we discussed earlier.

### Service matching scores

We mentioned that each service matching is given a score. The score is a Python tuple:

#### Score

```python
(
  close_match,
  total_matching_score,
  error_score,
  matched_over_total_score,
  meets_low_requirements
)
```

- `close_match` is a boolean and True only if all of the following are True:
  - `total_matching` is greater than 8
  - the absolute of `mean_time_error` is less than 1.0
  - `variance_time_error` is less than 2.0
- `total_matching_score` is an integer that is calculated by taking the integer value of `total_matching / 5`
- `error_score` is an integer calculated by taking the integer value of `mean_time_error / 0.4`
- `matched_over_total_score` is the integer of `total_matching / total_for_service`. "Total for service" is the total number of reports of the service.
- `meets_low_requirements` is a boolean that is True when `variance_time_error` is less than 3.0.

Some of the properties above (like `total_matching_score` and `error_score`) are meant to place values of certain intervals into "buckets", so that when sorting, values in the same bucket get equal precedence.
